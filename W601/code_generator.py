"""
Code Generator Module
Generates Python code for data analysis based on parsed intents
Based on reference: prompt.py (Excel data processing rules)
"""
import json
from typing import Dict, List, Any, Optional, Tuple
from openai import OpenAI
import config
from nlp_parser import AnalysisIntent


# Excel Data Processing Rules (from prompt.py)
EXCEL_PROCESSING_RULES = '''
**Excelæ•°æ®å¤„ç†è§„åˆ™é›†**
1. åŸºç¡€ä»£ç ç»“æ„è¦æ±‚ï¼š
    1.1 å¿…è¦çš„å¯¼å…¥å’Œè®¾ç½®ï¼š
        ```python
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)
```
    1.2 è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
        - åªéœ€è¦è¾“å‡ºä»£ç å³å¯ï¼Œæ— éœ€é¢å¤–çš„è§£é‡Š
        - è¾“å‡ºçš„ä»£ç ä¸è¦åŒ…å«ä»»ä½• Markdown æˆ–ä»£ç å—æ ‡è®°ï¼Œä»…æä¾›çº¯æ–‡æœ¬çš„ Python ä»£ç 
        - ç¦æ­¢è¾“å‡º"```python" æˆ–è€…"```"
        - æ‰€æœ‰ç”Ÿæˆçš„ç»“æœéƒ½å¿…é¡»é€šè¿‡"print"æ‰“å°åˆ°æ§åˆ¶å°

2. æ•°æ®æŸ¥è¯¢ä¸å¤„ç†è¦æ±‚ï¼š
    2.1 å¤šè¡Œæ•°æ®å¤„ç†ï¼š
        - ç”Ÿæˆä»£ç å‰éœ€è¦å…ˆæ ¹æ®æ•°æ®ç»“æ„åˆ¤æ–­ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„æ•°æ®æ˜¯å¤„äº"æŸèŒƒå›´å†…"è¿˜æ˜¯"æŸä¸ªå…·ä½“å€¼"
        - å¯¹ç»“æœé›†æ’åºæ—¶ï¼Œå¿…é¡»æ˜¾å¼æŒ‡å®š`ascending=False`ï¼ˆå€’åºï¼‰æˆ–`True`ï¼ˆå‡åºï¼‰ï¼Œé¿å…ä¾èµ–é»˜è®¤æ’åº
    2.2 å…³é”®å­—æ®µå¤„ç†ï¼š
        - æ—¶é—´å­—æ®µå¿…é¡»ç”¨`pd.to_datetime(..., errors='coerce').dt.normalize()`ç»Ÿä¸€è½¬æ¢ï¼Œå¹¶æå–å¹´æœˆæ—¥ç­‰åˆ†é‡è¿›è¡Œæ¯”è¾ƒ
        - å¯¹äºæ ‡è¯†ç¬¦ç±»å­—æ®µï¼Œå»ºè®®ä½¿ç”¨ .astype(str) è¿›è¡Œå­—ç¬¦ä¸²ç±»å‹è½¬æ¢
        - æ•°å€¼å­—æ®µå¿…é¡»ç”¨`pd.to_numeric(..., errors='coerce')`è½¬æ¢ï¼Œé¿å…å­—ç¬¦ä¸²æ¯”è¾ƒæ•°å€¼
        - ä¸ºäº†ç¡®ä¿å¯ä»¥æ‰§è¡Œæ•°å€¼è®¡ç®—ï¼Œè¯·ç”¨"pd.to_numeric(data, errors='coerce')"å°†æ•°æ®è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    2.3 æ•°æ®æ¸…æ´—å’Œå¤„ç†ï¼š
        - "DataFrame.fillna"æ–¹æ³•åœ¨ä½¿ç”¨"method"å‚æ•°æ—¶å·²è¿‡æ—¶è¢«å®˜æ–¹å¼ƒç”¨ï¼Œä½¿ç”¨ffill()æˆ–bfill()ä»£æ›¿
        - åˆ—åä¸­å¯èƒ½å‡ºç°çš„ä¸‹åˆ’çº¿ã€å¤šä¸ªç©ºæ ¼ç­‰ç‰¹æ®Šå­—ç¬¦éœ€ä¿æŒç»“æ„ä¸å˜
    2.4 è¾“å‡ºè§„èŒƒï¼š
        - æ‰¹é‡è¾“å‡ºæ—¶é€è¡Œæ ¼å¼åŒ–æ‰“å°

3. ä»£ç å¥å£®æ€§è¦æ±‚ï¼š
    3.1 å¼‚å¸¸å¤„ç†ï¼š
        - ä»£ç éœ€è¦åŒ…å«å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œå¿…é¡»ç”¨try-exceptåŒ…è£¹æ•°æ®å¤„ç†é€»è¾‘
        - æ•è·KeyErrorç­‰å¸¸è§å¼‚å¸¸å¹¶ç»™å‡ºå‹å¥½æç¤º
        - æ‰“å°å¼‚å¸¸æ—¶éœ€åŒ…å«å…·ä½“é”™è¯¯ä¿¡æ¯
    3.2 æ•°æ®æ ¡éªŒï¼š
        - è¯»å–æ•°æ®åç«‹å³æ£€æŸ¥df.emptyï¼Œé¿å…æ“ä½œç©ºDataFrame
        - å¯¹å…³é”®ç­›é€‰å­—æ®µå…ˆç¡®è®¤å­˜åœ¨æ€§

4. å‘½åè§„èŒƒï¼š
    4.1 å˜é‡å’Œå‡½æ•°å‘½åï¼š
        - é¿å…ä½¿ç”¨ç¬¦å·å¦‚#ï¼Œå› ä¸ºå®ƒæ˜¯æ³¨é‡Šç¬¦å·
        - é¿å…ä½¿ç”¨ä¸­æ–‡å­—ç¬¦å‘½åå˜é‡
        - ä½¿ç”¨æœ‰æ„ä¹‰çš„è‹±æ–‡å˜é‡åï¼Œå¦‚filtered_dfã€result_dataç­‰

5. é—®é¢˜æ‹†è§£åŸåˆ™ï¼š
    5.1 åˆ†æç”¨æˆ·éœ€æ±‚ï¼š
        - å…ˆè§£æç”¨æˆ·é—®é¢˜çš„å…³é”®ç»´åº¦
        - å°†è‡ªç„¶è¯­è¨€æè¿°è½¬åŒ–ä¸ºå¯¹åº”çš„pandasæ“ä½œé“¾
    5.2 é˜²å¾¡æ€§ç¼–ç¨‹ï¼š
        - å‡è®¾åŸå§‹æ•°æ®å¯èƒ½å­˜åœ¨ç¼ºå¤±å€¼ã€ç±»å‹æ··ä¹±æˆ–ç‰¹æ®Šå­—ç¬¦
'''


class CodeGenerator:
    """Generate Python code for data analysis"""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        ) if config.OPENAI_API_KEY else None
        
        self.system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªPythonæ•°æ®åˆ†æä»£ç ç”Ÿæˆä¸“å®¶ã€‚

æ ¹æ®ç”¨æˆ·çš„åˆ†æéœ€æ±‚ï¼Œç”Ÿæˆå®Œæ•´ã€å¯æ‰§è¡Œçš„Pythonä»£ç ã€‚

{EXCEL_PROCESSING_RULES}

é¢å¤–è¦æ±‚ï¼š
1. åœ¨ä»£ç å¼€å¤´å£°æ˜ä½¿ç”¨çš„åˆ—ï¼šused_columns = ["åˆ—å1", "åˆ—å2", ...]
2. åˆ†æç»“æœä¿å­˜åˆ° `analysis_result` å˜é‡ï¼ˆDataFrameã€Seriesæˆ–æ•°å€¼ï¼‰
3. å¦‚æœç”Ÿæˆå›¾è¡¨ï¼Œä¿å­˜åˆ° `figure` å˜é‡
4. ä½¿ç”¨matplotlibè¿›è¡Œå¯è§†åŒ–ï¼Œè®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
5. å›¾è¡¨éœ€è¦æœ‰æ ‡é¢˜ã€è½´æ ‡ç­¾

è¾“å‡ºæ ¼å¼ï¼šåªè¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«markdownæ ¼å¼æ ‡è®°ã€‚"""

    def generate_code(
        self, 
        query: str,
        intent: AnalysisIntent,
        file_info: Dict[str, Any],
        df_variable: str = "df",
        html_name: str = None
    ) -> Tuple[str, List[str]]:
        """
        Generate Python analysis code
        Returns: (code_string, used_columns)
        """
        if self.client:
            return self._llm_generate(query, intent, file_info, df_variable, html_name)
        else:
            return self._template_generate(intent, file_info, df_variable)
    
    def _llm_generate(
        self, 
        query: str,
        intent: AnalysisIntent,
        file_info: Dict[str, Any],
        df_variable: str,
        html_name: str = None
    ) -> Tuple[str, List[str]]:
        """Generate code using LLM"""
        
        columns_desc = self._format_columns_info(file_info)
        
        # Add Plotly chart generation hint if visualization needed
        chart_hint = ""
        if intent.visualization and html_name:
            chart_hint = f'''
å¦‚æœéœ€è¦ç”Ÿæˆå›¾è¡¨ï¼Œå¯ä»¥ä½¿ç”¨plotlyç”Ÿæˆå¯äº¤äº’çš„å›¾è¡¨ï¼š
- import plotly.graph_objects as go
- ä½¿ç”¨ go.Figure åˆ›å»ºå›¾è¡¨
- modeå‚æ•°å€¼ä¸º"lines+markers+text"ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
- fig.update_layoutçš„titleï¼ˆéœ€è¦å±…ä¸­å±•ç¤ºï¼‰ã€xaxis_titleã€yaxis_titleä¸å¾—ç¼ºå¤±
- Xè½´çš„æ•°æ®éœ€è¦ä»å°åˆ°å¤§è¿›è¡Œæ’åºåå†ç»˜åˆ¶å›¾è¡¨
- å¦‚æœä½¿ç”¨plotlyï¼Œå°†figureè®¾ä¸ºfigå¯¹è±¡
'''
        
        prompt = f"""ç”¨æˆ·éœ€æ±‚ï¼š{query}

åˆ†ææ„å›¾ï¼š
- æ“ä½œç±»å‹ï¼š{intent.operation}
- ç›®æ ‡åˆ—ï¼š{intent.target_columns}
- åˆ†ç»„åˆ—ï¼š{intent.group_by}
- ç­›é€‰æ¡ä»¶ï¼š{intent.filter_conditions}
- æ’åºï¼š{intent.sort_by} ({intent.sort_order})
- èšåˆæ–¹å¼ï¼š{intent.aggregations}
- å¯è§†åŒ–ï¼š{intent.visualization}

å¯ç”¨æ•°æ®ï¼ˆDataFrameå˜é‡åä¸º `{df_variable}`ï¼‰ï¼š
{columns_desc}
{chart_hint}
è¯·ç”Ÿæˆå®Œæ•´çš„Pythonåˆ†æä»£ç ã€‚è®°ä½ï¼š
1. åœ¨ä»£ç å¼€å¤´å£°æ˜ used_columns åˆ—è¡¨ï¼Œåˆ—å‡ºå®é™…ä½¿ç”¨çš„åˆ—å
2. åˆ†æç»“æœå­˜å…¥ analysis_result å˜é‡
3. å›¾è¡¨å­˜å…¥ figure å˜é‡ï¼ˆå¦‚æœæœ‰ï¼‰
4. ä½¿ç”¨ä¸­æ–‡æ³¨é‡Šè¯´æ˜æ¯ä¸ªæ­¥éª¤
5. æ·»åŠ æ•°æ®ç±»å‹è½¬æ¢å’Œé”™è¯¯å¤„ç†
6. æ•°å€¼åˆ—ç”¨ pd.to_numeric(..., errors='coerce') è½¬æ¢
7. æ—¥æœŸåˆ—ç”¨ pd.to_datetime(..., errors='coerce') è½¬æ¢"""

        try:
            response = self.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2
            )
            
            code = response.choices[0].message.content
            code = self._clean_code(code)
            used_columns = self._extract_used_columns(code)
            
            return code, used_columns
            
        except Exception as e:
            print(f"Code generation error: {e}")
            return self._template_generate(intent, file_info, df_variable)
    
    def _template_generate(
        self,
        intent: AnalysisIntent,
        file_info: Dict[str, Any],
        df_variable: str
    ) -> Tuple[str, List[str]]:
        """Generate code using templates when LLM unavailable"""
        
        columns = self._get_column_names(file_info)
        numeric_cols = self._get_numeric_columns(file_info)
        non_numeric_cols = [c for c in columns if c not in numeric_cols]
        
        # Preferred column patterns for Chinese/English data
        value_keywords = ['é”€å”®é¢', 'é‡‘é¢', 'æ”¶å…¥', 'æ€»é¢', 'å‡€é¢', 'amount', 'revenue', 'sales', 'total', 'price']
        category_keywords = ['åŸå¸‚', 'åœ°åŒº', 'äº§å“', 'ç±»åˆ«', 'æ¸ é“', 'éƒ¨é—¨', 'city', 'region', 'product', 'category', 'channel']
        
        # Find best target column (prefer value-related columns)
        target_col = None
        for kw in value_keywords:
            for col in numeric_cols:
                if kw in col.lower():
                    target_col = col
                    break
            if target_col:
                break
        if not target_col:
            target_col = numeric_cols[0] if numeric_cols else (columns[0] if columns else "value")
        
        # Find best group column (prefer categorical columns, avoid dates)
        group_col = None
        for kw in category_keywords:
            for col in non_numeric_cols:
                if kw in col.lower() and 'æ—¥æœŸ' not in col and 'date' not in col.lower():
                    group_col = col
                    break
            if group_col:
                break
        if not group_col:
            # Filter out date columns
            categorical_cols = [c for c in non_numeric_cols if 'æ—¥æœŸ' not in c and 'date' not in c.lower() and 'æ—¶é—´' not in c]
            group_col = categorical_cols[0] if categorical_cols else (non_numeric_cols[0] if non_numeric_cols else (columns[0] if columns else "category"))
        
        # Use intent columns if available AND not empty AND exist
        if intent.target_columns and intent.target_columns[0] and intent.target_columns[0].strip():
            if intent.target_columns[0] in columns:
                target_col = intent.target_columns[0]
        if intent.group_by and intent.group_by[0] and intent.group_by[0].strip():
            if intent.group_by[0] in columns:
                group_col = intent.group_by[0]
            
        used_columns = [target_col]
        if group_col != target_col:
            used_columns.append(group_col)
            
        templates = {
            "sum": self._sum_template,
            "average": self._average_template,
            "trend": self._trend_template,
            "group": self._group_template,
            "distribution": self._distribution_template,
            "compare": self._compare_template,
            "sort": self._sort_template,
            "filter": self._filter_template,
            "count": self._count_template,
            "general": self._general_template
        }
        
        template_func = templates.get(intent.operation, self._general_template)
        code = template_func(df_variable, target_col, group_col, intent)
        
        return code, used_columns
    
    def _format_columns_info(self, file_info: Dict[str, Any]) -> str:
        """Format column information for LLM prompt"""
        lines = []
        for sheet in file_info.get('sheets', []):
            lines.append(f"å·¥ä½œè¡¨: {sheet['sheet_name']} ({sheet['row_count']}è¡Œ)")
            for col in sheet.get('columns', []):
                samples = str(col.get('sample_values', []))[:50]
                lines.append(f"  - {col['name']} ({col['dtype']}): ç¤ºä¾‹={samples}")
        return "\n".join(lines)
    
    def _get_column_names(self, file_info: Dict[str, Any]) -> List[str]:
        """Extract column names from file info"""
        columns = []
        for sheet in file_info.get('sheets', []):
            for col in sheet.get('columns', []):
                columns.append(col['name'])
        return columns
    
    def _get_numeric_columns(self, file_info: Dict[str, Any]) -> List[str]:
        """Extract numeric column names"""
        numeric = []
        for sheet in file_info.get('sheets', []):
            for col in sheet.get('columns', []):
                if 'int' in col['dtype'] or 'float' in col['dtype']:
                    numeric.append(col['name'])
        return numeric
    
    def _clean_code(self, code: str) -> str:
        """Remove markdown formatting from code"""
        code = code.strip()
        if code.startswith("```python"):
            code = code[9:]
        elif code.startswith("```"):
            code = code[3:]
        if code.endswith("```"):
            code = code[:-3]
        return code.strip()
    
    def _extract_used_columns(self, code: str) -> List[str]:
        """Extract used_columns from generated code"""
        import re
        match = re.search(r'used_columns\s*=\s*\[(.*?)\]', code, re.DOTALL)
        if match:
            cols_str = match.group(1)
            cols = re.findall(r'["\']([^"\']+)["\']', cols_str)
            return cols
        return []
    
    def _get_matplotlib_chinese_setup(self) -> str:
        """Return matplotlib Chinese font setup code with professional styling"""
        return '''import matplotlib.pyplot as plt
import matplotlib
from matplotlib import cm

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Heiti TC', 'STHeiti', 'Microsoft YaHei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ä¸“ä¸šå›¾è¡¨æ ·å¼
plt.rcParams['figure.facecolor'] = '#f8f9fa'
plt.rcParams['axes.facecolor'] = '#ffffff'
plt.rcParams['axes.edgecolor'] = '#cccccc'
plt.rcParams['axes.labelcolor'] = '#333333'
plt.rcParams['xtick.color'] = '#666666'
plt.rcParams['ytick.color'] = '#666666'
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 11
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3
plt.rcParams['grid.linestyle'] = '--'

# ä¸“ä¸šé…è‰²æ–¹æ¡ˆ
COLORS = ['#4C78A8', '#F58518', '#E45756', '#72B7B2', '#54A24B', '#EECA3B', '#B279A2', '#FF9DA6']
'''

    # Template methods with improved data handling
    def _sum_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# æ•°æ®æ±‚å’Œåˆ†æ
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

# åŠ¨æ€é€‰æ‹©åˆ—
all_cols = {df_var}.columns.tolist()
numeric_cols = {df_var}.select_dtypes(include=[np.number]).columns.tolist()
non_numeric_cols = [c for c in all_cols if c not in numeric_cols]

# é€‰æ‹©ç›®æ ‡åˆ—å’Œåˆ†ç»„åˆ—
target_col = "{target}" if "{target}" in all_cols else (numeric_cols[0] if numeric_cols else all_cols[0])
group_col = "{group}" if "{group}" in all_cols else (non_numeric_cols[0] if non_numeric_cols else all_cols[0])

used_columns = [target_col, group_col]
print(f"ä½¿ç”¨åˆ—: æ•°å€¼åˆ—={{target_col}}, åˆ†ç»„åˆ—={{group_col}}")

# æ£€æŸ¥æ•°æ®
if {df_var}.empty:
    print("è­¦å‘Š: æ•°æ®ä¸ºç©º")
    analysis_result = pd.DataFrame()
else:
    # æ•°æ®ç±»å‹è½¬æ¢
    {df_var}[target_col] = pd.to_numeric({df_var}[target_col], errors='coerce')
    
    # åˆ†ç»„æ±‚å’Œ
    analysis_result = {df_var}.groupby(group_col)[target_col].sum().reset_index()
    analysis_result.columns = [group_col, f"{{target_col}}_æ€»è®¡"]
    analysis_result = analysis_result.sort_values(f"{{target_col}}_æ€»è®¡", ascending=False)
    
    print("\\n=== åˆ†ç»„æ±‚å’Œç»“æœ ===")
    print(analysis_result.to_string(index=False))
    print(f"\\næ€»è®¡: {{analysis_result[f'{{target_col}}_æ€»è®¡'].sum():,.2f}}")
    
    # å¯è§†åŒ–
    figure, ax = plt.subplots(figsize=(12, 7))
    figure.patch.set_facecolor('#f8f9fa')
    
    x_labels = analysis_result[group_col].astype(str)
    x_pos = range(len(x_labels))
    values = analysis_result[f"{{target_col}}_æ€»è®¡"]
    
    # æ¸å˜è‰²æŸ±çŠ¶å›¾
    colors = [COLORS[i % len(COLORS)] for i in range(len(x_labels))]
    bars = ax.bar(x_pos, values, color=colors, edgecolor='white', linewidth=1.5, width=0.7)
    
    ax.set_xticks(x_pos)
    ax.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=11)
    ax.set_xlabel(group_col, fontsize=12, fontweight='bold')
    ax.set_ylabel(target_col, fontsize=12, fontweight='bold')
    ax.set_title(f"ğŸ“Š {{target_col}}ç»Ÿè®¡åˆ†æ - æŒ‰{{group_col}}åˆ†ç»„", fontsize=14, fontweight='bold', pad=20)
    
    # ç§»é™¤é¡¶éƒ¨å’Œå³ä¾§è¾¹æ¡†
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    max_val = max(values)
    for bar, val in zip(bars, values):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max_val*0.02, 
                f'{{val:,.0f}}', ha='center', va='bottom', fontsize=10, fontweight='bold', color='#333')
    
    # æ·»åŠ æ€»è®¡çº¿
    avg_val = values.mean()
    ax.axhline(y=avg_val, color='#E45756', linestyle='--', linewidth=2, alpha=0.7, label=f'å¹³å‡å€¼: {{avg_val:,.0f}}')
    ax.legend(loc='upper right', framealpha=0.9)
    
    plt.tight_layout(pad=2.0)
'''
    
    def _average_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# å¹³å‡å€¼åˆ†æ
used_columns = ["{target}", "{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    {df_var}["{target}"] = pd.to_numeric({df_var}["{target}"], errors='coerce')
    
    analysis_result = {df_var}.groupby("{group}")["{target}"].mean().reset_index()
    analysis_result.columns = ["{group}", "{target}_å¹³å‡"]
    analysis_result = analysis_result.sort_values("{target}_å¹³å‡", ascending=False)
    
    print("=== å¹³å‡å€¼åˆ†æç»“æœ ===")
    print(analysis_result.to_string(index=False))
    print(f"\\næ€»ä½“å¹³å‡: {{{df_var}['{target}'].mean():,.2f}}")
    
    figure, ax = plt.subplots(figsize=(10, 6))
    ax.bar(analysis_result["{group}"], analysis_result["{target}_å¹³å‡"], color='steelblue')
    ax.axhline(y={df_var}["{target}"].mean(), color='red', linestyle='--', label='æ€»ä½“å¹³å‡')
    ax.set_xlabel("{group}")
    ax.set_ylabel("{target} å¹³å‡å€¼")
    ax.set_title("{target}å¹³å‡å€¼åˆ†æ - æŒ‰{group}")
    ax.legend()
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _trend_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# è¶‹åŠ¿åˆ†æ
used_columns = ["{target}", "{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    {df_var}["{target}"] = pd.to_numeric({df_var}["{target}"], errors='coerce')
    
    # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸç±»å‹
    if {df_var}["{group}"].dtype == 'object':
        {df_var}["{group}"] = pd.to_datetime({df_var}["{group}"], errors='coerce')
    
    # æŒ‰æ—¶é—´åˆ†ç»„èšåˆ
    if pd.api.types.is_datetime64_any_dtype({df_var}["{group}"]):
        analysis_result = {df_var}.groupby({df_var}["{group}"].dt.to_period('M'))["{target}"].sum().reset_index()
        analysis_result["{group}"] = analysis_result["{group}"].astype(str)
    else:
        analysis_result = {df_var}.groupby("{group}")["{target}"].sum().reset_index()
    
    analysis_result = analysis_result.sort_values("{group}", ascending=True)
    
    print("=== è¶‹åŠ¿åˆ†æç»“æœ ===")
    print(analysis_result.to_string(index=False))
    
    figure, ax = plt.subplots(figsize=(12, 6))
    ax.plot(analysis_result["{group}"], analysis_result["{target}"], marker='o', linewidth=2, markersize=6)
    ax.fill_between(range(len(analysis_result)), analysis_result["{target}"], alpha=0.3)
    ax.set_xlabel("{group}")
    ax.set_ylabel("{target}")
    ax.set_title("{target}è¶‹åŠ¿åˆ†æ")
    ax.grid(True, alpha=0.3)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _group_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# åˆ†ç»„ç»Ÿè®¡åˆ†æ
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

# åŠ¨æ€é€‰æ‹©åˆ—
all_cols = {df_var}.columns.tolist()
numeric_cols = {df_var}.select_dtypes(include=[np.number]).columns.tolist()
non_numeric_cols = [c for c in all_cols if c not in numeric_cols]

target_col = "{target}" if "{target}" in all_cols else (numeric_cols[0] if numeric_cols else all_cols[0])
group_col = "{group}" if "{group}" in all_cols else (non_numeric_cols[0] if non_numeric_cols else all_cols[0])

used_columns = [target_col, group_col]
print(f"ä½¿ç”¨åˆ—: æ•°å€¼åˆ—={{target_col}}, åˆ†ç»„åˆ—={{group_col}}")

if {df_var}.empty:
    print("è­¦å‘Š: æ•°æ®ä¸ºç©º")
    analysis_result = pd.DataFrame()
else:
    {df_var}[target_col] = pd.to_numeric({df_var}[target_col], errors='coerce')
    
    analysis_result = {df_var}.groupby(group_col)[target_col].agg(['sum', 'mean', 'count', 'min', 'max']).reset_index()
    analysis_result.columns = [group_col, "æ€»å’Œ", "å¹³å‡", "è®¡æ•°", "æœ€å°", "æœ€å¤§"]
    analysis_result = analysis_result.sort_values("æ€»å’Œ", ascending=False)
    
    print("\\n=== åˆ†ç»„ç»Ÿè®¡ç»“æœ ===")
    print(analysis_result.to_string(index=False))
    
    figure, axes = plt.subplots(1, 2, figsize=(14, 6))
    figure.patch.set_facecolor('#f8f9fa')
    
    x_labels = analysis_result[group_col].astype(str)
    x_pos = range(len(x_labels))
    
    # æ€»å’ŒæŸ±çŠ¶å›¾ - æ¸å˜è‰²
    colors1 = [COLORS[i % len(COLORS)] for i in range(len(x_labels))]
    bars1 = axes[0].bar(x_pos, analysis_result["æ€»å’Œ"], color=colors1, edgecolor='white', linewidth=1.2)
    axes[0].set_xticks(x_pos)
    axes[0].set_xticklabels(x_labels, rotation=45, ha='right')
    axes[0].set_title(f"ğŸ“Š å„{{group_col}}çš„{{target_col}}æ€»å’Œ", fontsize=13, fontweight='bold', pad=15)
    axes[0].set_xlabel(group_col, fontsize=11)
    axes[0].set_ylabel("æ€»å’Œ", fontsize=11)
    axes[0].spines['top'].set_visible(False)
    axes[0].spines['right'].set_visible(False)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, val in zip(bars1, analysis_result["æ€»å’Œ"]):
        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(analysis_result["æ€»å’Œ"])*0.02, 
                    f'{{val:,.0f}}', ha='center', va='bottom', fontsize=9, fontweight='bold', color='#333')
    
    # è®¡æ•°æŸ±çŠ¶å›¾
    colors2 = ['#72B7B2'] * len(x_labels)
    bars2 = axes[1].bar(x_pos, analysis_result["è®¡æ•°"], color=colors2, edgecolor='white', linewidth=1.2)
    axes[1].set_xticks(x_pos)
    axes[1].set_xticklabels(x_labels, rotation=45, ha='right')
    axes[1].set_title(f"ğŸ“ˆ å„{{group_col}}çš„è®°å½•æ•°", fontsize=13, fontweight='bold', pad=15)
    axes[1].set_xlabel(group_col, fontsize=11)
    axes[1].set_ylabel("è®°å½•æ•°", fontsize=11)
    axes[1].spines['top'].set_visible(False)
    axes[1].spines['right'].set_visible(False)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, val in zip(bars2, analysis_result["è®¡æ•°"]):
        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(analysis_result["è®¡æ•°"])*0.02, 
                    f'{{int(val)}}', ha='center', va='bottom', fontsize=10, fontweight='bold', color='#333')
    
    plt.tight_layout(pad=2.0)
'''

    def _distribution_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# åˆ†å¸ƒåˆ†æ
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

# åŠ¨æ€é€‰æ‹©åˆ—
all_cols = {df_var}.columns.tolist()
numeric_cols = {df_var}.select_dtypes(include=[np.number]).columns.tolist()
non_numeric_cols = [c for c in all_cols if c not in numeric_cols]

target_col = "{target}" if "{target}" in all_cols else (numeric_cols[0] if numeric_cols else all_cols[0])
group_col = "{group}" if "{group}" in all_cols else (non_numeric_cols[0] if non_numeric_cols else all_cols[0])

used_columns = [target_col, group_col]
print(f"ä½¿ç”¨åˆ—: æ•°å€¼åˆ—={{target_col}}, åˆ†ç»„åˆ—={{group_col}}")

if {df_var}.empty:
    print("è­¦å‘Š: æ•°æ®ä¸ºç©º")
    analysis_result = pd.DataFrame()
else:
    {df_var}[target_col] = pd.to_numeric({df_var}[target_col], errors='coerce')
    
    analysis_result = {df_var}.groupby(group_col)[target_col].sum().reset_index()
    analysis_result.columns = [group_col, "æ•°å€¼"]
    analysis_result["å æ¯”"] = (analysis_result["æ•°å€¼"] / analysis_result["æ•°å€¼"].sum() * 100).round(2)
    analysis_result = analysis_result.sort_values("æ•°å€¼", ascending=False)
    
    print("\\n=== åˆ†å¸ƒåˆ†æç»“æœ ===")
    for _, row in analysis_result.iterrows():
        print(f"{{row[group_col]}}: {{row['æ•°å€¼']:,.0f}} ({{row['å æ¯”']}}%)")
    
    # åˆ›å»ºä¸“ä¸šé¥¼å›¾
    figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))
    figure.patch.set_facecolor('#f8f9fa')
    
    # é¥¼å›¾
    colors = COLORS[:len(analysis_result)]
    explode = [0.02] * len(analysis_result)
    explode[0] = 0.08  # çªå‡ºæœ€å¤§é¡¹
    
    wedges, texts, autotexts = ax1.pie(
        analysis_result["æ•°å€¼"], 
        labels=analysis_result[group_col].astype(str),
        autopct='%1.1f%%',
        colors=colors,
        startangle=90,
        explode=explode,
        shadow=True,
        textprops={{'fontsize': 10}}
    )
    for autotext in autotexts:
        autotext.set_fontweight('bold')
        autotext.set_fontsize(9)
    ax1.set_title(f"ğŸ¥§ {{target_col}}åˆ†å¸ƒ - æŒ‰{{group_col}}", fontsize=14, fontweight='bold', pad=20)
    
    # æ°´å¹³æŸ±çŠ¶å›¾
    y_pos = range(len(analysis_result))
    ax2.barh(y_pos, analysis_result["æ•°å€¼"], color=colors, edgecolor='white', height=0.7)
    ax2.set_yticks(y_pos)
    ax2.set_yticklabels(analysis_result[group_col].astype(str), fontsize=10)
    ax2.set_xlabel("æ•°å€¼", fontsize=11, fontweight='bold')
    ax2.set_title(f"ğŸ“Š {{target_col}}å¯¹æ¯”", fontsize=14, fontweight='bold', pad=20)
    ax2.spines['top'].set_visible(False)
    ax2.spines['right'].set_visible(False)
    ax2.invert_yaxis()
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (val, pct) in enumerate(zip(analysis_result["æ•°å€¼"], analysis_result["å æ¯”"])):
        ax2.text(val + max(analysis_result["æ•°å€¼"])*0.02, i, f'{{val:,.0f}} ({{pct}}%)', 
                va='center', fontsize=9, fontweight='bold', color='#333')
    
    plt.tight_layout(pad=2.0)
'''

    def _compare_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# å¯¹æ¯”åˆ†æ
used_columns = ["{target}", "{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    {df_var}["{target}"] = pd.to_numeric({df_var}["{target}"], errors='coerce')
    
    analysis_result = {df_var}.groupby("{group}")["{target}"].sum().sort_values(ascending=False).reset_index()
    analysis_result.columns = ["{group}", "{target}"]
    
    print("=== å¯¹æ¯”åˆ†æç»“æœ ===")
    print(analysis_result.to_string(index=False))
    
    figure, ax = plt.subplots(figsize=(12, 6))
    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(analysis_result)))
    bars = ax.barh(analysis_result["{group}"], analysis_result["{target}"], color=colors)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, val in zip(bars, analysis_result["{target}"]):
        ax.text(val, bar.get_y() + bar.get_height()/2, f'{{val:,.0f}}', 
                va='center', ha='left', fontsize=9)
    
    ax.set_xlabel("{target}")
    ax.set_ylabel("{group}")
    ax.set_title("{group}å¯¹æ¯”åˆ†æ - {target}")
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _sort_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        ascending = intent.sort_order == "asc"
        return f'''# æ’åºåˆ†æ (Top N)
used_columns = ["{target}", "{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    {df_var}["{target}"] = pd.to_numeric({df_var}["{target}"], errors='coerce')
    
    # æ’åºå¹¶å–Top 10
    analysis_result = {df_var}.sort_values("{target}", ascending={ascending}).head(10)
    
    print("=== Top 10 æ’å ===")
    for i, (_, row) in enumerate(analysis_result.iterrows(), 1):
        print(f"{{i}}. {{row.get('{group}', 'N/A')}}: {{row['{target}']:,.2f}}")
    
    figure, ax = plt.subplots(figsize=(10, 6))
    y_pos = range(len(analysis_result))
    ax.barh(y_pos, analysis_result["{target}"].values, color='steelblue')
    ax.set_yticks(y_pos)
    ax.set_yticklabels(analysis_result["{group}"].values if "{group}" in analysis_result.columns else analysis_result.index)
    ax.invert_yaxis()
    ax.set_xlabel("{target}")
    ax.set_title("Top 10 {target}æ’å")
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _filter_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# ç­›é€‰åˆ†æ
used_columns = ["{target}", "{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    {df_var}["{target}"] = pd.to_numeric({df_var}["{target}"], errors='coerce')
    
    # ç­›é€‰æ•°æ®
    analysis_result = {df_var}.copy()
    
    print("=== ç­›é€‰ç»“æœ ===")
    print(f"ç­›é€‰åæ•°æ®é‡: {{len(analysis_result)}} æ¡")
    print(analysis_result.head(20).to_string(index=False))
    
    figure, ax = plt.subplots(figsize=(10, 6))
    if len(analysis_result) > 0:
        analysis_result["{target}"].hist(ax=ax, bins=20, color='steelblue', edgecolor='white')
    ax.set_xlabel("{target}")
    ax.set_ylabel("é¢‘æ•°")
    ax.set_title("{target}åˆ†å¸ƒç›´æ–¹å›¾")
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _count_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# è®¡æ•°åˆ†æ
used_columns = ["{group}"]

import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

try:
    if {df_var}.empty:
        raise ValueError("æ•°æ®ä¸ºç©º")
    
    analysis_result = {df_var}["{group}"].value_counts().reset_index()
    analysis_result.columns = ["{group}", "è®¡æ•°"]
    
    print("=== è®¡æ•°ç»Ÿè®¡ç»“æœ ===")
    print(analysis_result.to_string(index=False))
    print(f"\\næ€»è®¡: {{analysis_result['è®¡æ•°'].sum()}}")
    
    figure, ax = plt.subplots(figsize=(10, 6))
    ax.bar(analysis_result["{group}"].astype(str), analysis_result["è®¡æ•°"], color='steelblue')
    ax.set_xlabel("{group}")
    ax.set_ylabel("è®¡æ•°")
    ax.set_title("{group}è®¡æ•°ç»Ÿè®¡")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
except Exception as e:
    print(f"åˆ†æé”™è¯¯: {{e}}")
    analysis_result = None
'''

    def _general_template(self, df_var: str, target: str, group: str, intent: AnalysisIntent) -> str:
        return f'''# æ•°æ®æ¦‚è§ˆåˆ†æ
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)
{self._get_matplotlib_chinese_setup()}

# è·å–æ‰€æœ‰åˆ—ä¿¡æ¯
all_cols = {df_var}.columns.tolist()
numeric_cols = {df_var}.select_dtypes(include=[np.number]).columns.tolist()
used_columns = all_cols[:5]  # ä½¿ç”¨å‰5åˆ—ä½œä¸ºç¤ºä¾‹

print("=== æ•°æ®æ¦‚è§ˆ ===")
print(f"æ•°æ®ç»´åº¦: {{{df_var}.shape[0]}} è¡Œ x {{{df_var}.shape[1]}} åˆ—")
print(f"\\næ‰€æœ‰åˆ—å: {{all_cols}}")
print(f"æ•°å€¼åˆ—: {{numeric_cols}}")

print("\\n=== æ•°æ®é¢„è§ˆ (å‰5è¡Œ) ===")
print({df_var}.head().to_string())

print("\\n=== æ•°å€¼åˆ—ç»Ÿè®¡ ===")
if len(numeric_cols) > 0:
    print({df_var}[numeric_cols].describe().to_string())
else:
    print("æ²¡æœ‰æ•°å€¼åˆ—")

# åˆ›å»ºåˆ†æç»“æœ DataFrame
analysis_result = {df_var}.describe().T.reset_index()
analysis_result.columns = ['åˆ—å'] + list(analysis_result.columns[1:])

print("\\n=== ç»Ÿè®¡æ‘˜è¦ ===")
summary = {{
    "æ€»è¡Œæ•°": len({df_var}),
    "æ€»åˆ—æ•°": len({df_var}.columns),
    "æ•°å€¼åˆ—æ•°": len(numeric_cols),
    "ç¼ºå¤±å€¼æ€»æ•°": int({df_var}.isna().sum().sum())
}}
for k, v in summary.items():
    print(f"{{k}}: {{v}}")

# å¯è§†åŒ–
figure, axes = plt.subplots(1, 2, figsize=(14, 5))

# æ•°æ®ç±»å‹åˆ†å¸ƒ
type_counts = {df_var}.dtypes.value_counts()
axes[0].pie(type_counts.values, labels=type_counts.index.astype(str), autopct='%1.1f%%')
axes[0].set_title("æ•°æ®ç±»å‹åˆ†å¸ƒ")

# ç¼ºå¤±å€¼æƒ…å†µæˆ–æ•°å€¼åˆ†å¸ƒ
missing = {df_var}.isna().sum()
missing = missing[missing > 0]
if len(missing) > 0:
    axes[1].barh(missing.index.astype(str), missing.values, color='coral')
    axes[1].set_title("ç¼ºå¤±å€¼ç»Ÿè®¡")
    axes[1].set_xlabel("ç¼ºå¤±æ•°é‡")
elif len(numeric_cols) > 0:
    {df_var}[numeric_cols[0]].hist(ax=axes[1], bins=20, color='steelblue', edgecolor='white')
    axes[1].set_title(f"{{numeric_cols[0]}} åˆ†å¸ƒ")
else:
    axes[1].text(0.5, 0.5, 'æ•°æ®å®Œæ•´', ha='center', va='center', fontsize=14)
    axes[1].set_title("æ•°æ®è´¨é‡")

plt.tight_layout()
print("\\nåˆ†æå®Œæˆ!")
'''
