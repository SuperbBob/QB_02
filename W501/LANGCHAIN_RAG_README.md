# LangChain RAG é—®ç­”ç³»ç»Ÿ

ä¸€ä¸ªç®€å•çš„åŸºäº LangChain çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰é—®ç­”åº”ç”¨ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸ“„ **PDF æ–‡æ¡£åŠ è½½**: æ”¯æŒåŠ è½½å•ä¸ª PDF æˆ–æ•´ä¸ªæ–‡ä»¶å¤¹
- ğŸ” **æ™ºèƒ½åˆ†å—**: ä½¿ç”¨ RecursiveCharacterTextSplitter è¿›è¡Œæ–‡æœ¬åˆ†å—
- ğŸ’¾ **å‘é‡å­˜å‚¨**: ä½¿ç”¨ Chroma ä½œä¸ºæœ¬åœ°å‘é‡æ•°æ®åº“ï¼ˆæ— éœ€å¤–éƒ¨æœåŠ¡ï¼‰
- ğŸ¤– **çµæ´»çš„ LLM**: æ”¯æŒ Ollamaï¼ˆæœ¬åœ°ï¼‰å’Œ OpenAI
- ğŸ”„ **æŒä¹…åŒ–å­˜å‚¨**: è‡ªåŠ¨ä¿å­˜å‘é‡æ•°æ®åº“ï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ

```bash
# å¯åŠ¨ Ollama
ollama serve

# æ‹‰å–éœ€è¦çš„æ¨¡å‹
ollama pull llama3.2
ollama pull nomic-embed-text
```

### 3. è¿è¡Œäº¤äº’å¼æ¼”ç¤º

```bash
cd W501
python langchain_demo.py
```

## ä»£ç ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ç”¨æ³•

```python
from langchain_rag import create_rag

# åˆ›å»º RAG å®ä¾‹ï¼ˆä½¿ç”¨ Ollamaï¼‰
rag = create_rag(use_ollama=True)

# åŠ è½½ PDF æ–‡æ¡£
rag.ingest_pdf("path/to/document.pdf")

# æé—®
result = rag.query("è¿™ç¯‡æ–‡æ¡£è®²äº†ä»€ä¹ˆï¼Ÿ")
print(result["answer"])
```

### åŠ è½½å¤šä¸ªæ–‡æ¡£

```python
# åŠ è½½æ•´ä¸ªæ–‡ä»¶å¤¹çš„ PDF
rag.ingest_directory("path/to/pdf_folder/")

# æˆ–è€…åŠ è½½å¤šä¸ªæŒ‡å®šæ–‡ä»¶
from langchain_rag import LangChainRAG

rag = LangChainRAG()
chunks = rag.load_multiple_pdfs([
    "doc1.pdf",
    "doc2.pdf",
    "doc3.pdf"
])
rag.add_documents(chunks)
```

### ä½¿ç”¨ OpenAI

```python
# è®¾ç½®ç¯å¢ƒå˜é‡
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"

# åˆ›å»ºä½¿ç”¨ OpenAI çš„ RAG
rag = create_rag(use_ollama=False)
```

### ç›¸ä¼¼åº¦æœç´¢

```python
# ä¸ä½¿ç”¨ LLMï¼Œç›´æ¥æœç´¢ç›¸å…³å†…å®¹
docs = rag.similarity_search("å…³é”®è¯", k=5)
for doc in docs:
    print(doc.page_content)
```

## é…ç½®é€‰é¡¹

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `persist_directory` | `./chroma_db` | å‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„ |
| `chunk_size` | 1000 | æ–‡æœ¬åˆ†å—å¤§å° |
| `chunk_overlap` | 200 | åˆ†å—é‡å å¤§å° |
| `use_ollama` | True | æ˜¯å¦ä½¿ç”¨ Ollama |
| `ollama_model` | `llama3.2` | Ollama LLM æ¨¡å‹ |
| `embedding_model` | `nomic-embed-text` | Embedding æ¨¡å‹ |

## ç›®å½•ç»“æ„

```
W501/
â”œâ”€â”€ langchain_rag.py          # RAG æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ langchain_demo.py         # äº¤äº’å¼æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ chroma_db/                # å‘é‡æ•°æ®åº“ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â””â”€â”€ LANGCHAIN_RAG_README.md   # æœ¬æ–‡æ¡£
```

## ç¯å¢ƒå˜é‡

å¯é€‰çš„ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
# Ollama é…ç½®
OLLAMA_URL=http://localhost:11434

# OpenAI é…ç½®ï¼ˆå¦‚æœä½¿ç”¨ OpenAIï¼‰
OPENAI_API_KEY=your-api-key
OPENAI_BASE_URL=https://api.openai.com/v1
```

## æ³¨æ„äº‹é¡¹

1. é¦–æ¬¡è¿è¡Œæ—¶éœ€è¦ä¸‹è½½ embedding æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ
2. å‘é‡æ•°æ®åº“ä¼šè‡ªåŠ¨æŒä¹…åŒ–åˆ° `chroma_db` ç›®å½•
3. ä½¿ç”¨ `rag.clear_database()` å¯ä»¥æ¸…é™¤æ‰€æœ‰å·²ç´¢å¼•çš„æ–‡æ¡£

